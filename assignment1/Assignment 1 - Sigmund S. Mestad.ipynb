{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "![Task 1a - The gradient for Logistic Regression](task1a.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "![Task 1b - The gradient for Softmax Regression](task1b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2b)\n",
    "![Task 2b - Loss](task2b-binary-train-loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![Task 2c - Accuracy](task2c_binary_train_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "Early stop kicks in after 32 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2e)\n",
    "![Task 2e - Loss with and without shuffle](task2e_train_loss_with_shuffle.png)\n",
    "![Task 2e - Accuracy with and without shuffle](task2e_train_accuracy_shuffle_difference.png)\n",
    "\n",
    "The accuracy have less spikes when shuffeling because the network is robust and generilized when presented with a new batch of images every time. This makes it less vulnarable for some \"bad\" batch confusing the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3b)\n",
    "![Task 3b - Training and validation loss](task3b_softmax_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3c)\n",
    "![Task 3c - Training and validation accuracy](task3c_softmax_train_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3d)\n",
    "The model doesn't show serious signs of overfitting. The validation accuracy seems to reach a platou at around 40-50 epochs (the early stop kicks in at 49). Doubling the number of epochs, we see that the training accuracy continues to grow, while the validation accuracy is completely flat (see plot below). A possible explaination of why the network doesn't seem to overfit could be because the model is too simple to learn all the details and noise of the training data which normally would lead to worse performance.  \n",
    "![Task 3d - Accuracy over 100 epochs](task3d_softmax_train_accuracy_overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "![Task 4a - Update term for softmax regression with L2 regularization](task4a.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "![Weights when lambda=0](task4b_softmax_weight.png)  \n",
    "![Weights when lambda=2](task4b_softmax_weight1.png)  \n",
    "The regularization term reduces all weights, reducing the effect of less common patterns. Weights with low consensus will diminish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4c)\n",
    "![Task 4c - Accuracy with different lambda values](task4c_l2_reg_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "The validation accuracy degrades when applying regularization because the model architecture is so simple. Making the model even more general, reduces its capacity to differnsiate the numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "![Task 4e - L2-normalization of weights](task4d_l2_reg_norms.png)\n",
    "\n",
    "It's clear that more regularization leads to smaller weights. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('datasyn': conda)",
   "metadata": {
    "interpreter": {
     "hash": "61cac86c2bfc606d9b2fa1e5cd01ab205e1685ca96b939dca918b923d329ec10"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}