{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "![](task1a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![](task2c_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "There is a total of 50880 parameters in the network of which 50240 are weights between the input layer and the hidden layer and 640 are weights between the hidden layer and the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3a - Improved weight initialization\n",
    "Early stop after 43/44 epochs compared to 47.  \n",
    "![](improved_weight_init.png)\n",
    "\n",
    "## Task 3b - Improved sigmoid function\n",
    "Early stop after 24 epochs.  \n",
    "![](improved_sigmoid.png)\n",
    "\n",
    "## Task 3c - Momentum\n",
    "Early stop after 19 epochs.  \n",
    "![](momentum.png)\n",
    "\n",
    "All three improvements significantly reduces convergance speed. With all three improvements early stop kicks in after 19 epochs compared to 47.  \n",
    "The improved weight initialization improves validation accuracy by a great deal from about 0.915 to almost 0.96.\n",
    "The improved simoid function seems to improve the validation accuracy with shuffeling just a tiny bit, and the momentum improves it some more. \n",
    "With the last improvement we also see a clearer difference between the acuracy with and without shuffeling, which makes sense because the momentum makes a connection between successive batches, thus reducing generality if not shuffeled between each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "To few hidden units (32) reduces the learning speed (faster iterations and convergence after 16/17 epochs), but also the accuracy down to 0.94-0.95  \n",
    "![](few_units.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "\n",
    "To many hidden unites (128) increases the learning speed (slower iterations and convergance after 20 epochs), but the accuracy increases slightly. In general however a too complex network will tend to overfit and thus reduce the accuracy.  \n",
    "![](too_many_units.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "In the network from task 3 there is 50880 parameters.  \n",
    "In the new network there is 51300 parameters. The network has two hidden layers of 60 nodes each.  \n",
    "![](task4d.png)  \n",
    "\n",
    "The new model gives about the same accuracy, but it converges alot faster.\n",
    "We can also see that it's overfitting, giving 100% accuracy on the training data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "![](task4e.png)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
